{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation and Fix Cycle\n",
    "\n",
    "This notebook demonstrates the generation, QC, and fix cycle for AP exam questions. The implementation details have been modularized into the `gen_fix_cycle` package for clarity and maintainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the first cell only once when you open the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "%rm -rf colab-example\n",
    "\n",
    "# Clone repo\n",
    "!git clone https://github.com/InceptTrilogy/colab-example.git\n",
    "%cd colab-example\n",
    "\n",
    "# Install package\n",
    "!pip install -e .\n",
    "\n",
    "# Add src to Python path\n",
    "import sys\n",
    "sys.path.append('/content/colab-example/src')\n",
    "\n",
    "# Install OpenAI for LLM integration\n",
    "!pip install openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the generation cycle parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_fix_cycle.cycle import CycleConfig, run_generation\n",
    "from gen_fix_cycle.models import Difficulty\n",
    "\n",
    "# Example article text\n",
    "article = \"\"\"\n",
    "Your article text here...\n",
    "\"\"\"\n",
    "\n",
    "# Configure the generation cycle\n",
    "config = CycleConfig(\n",
    "    course=\"APHUMG\",\n",
    "    article=article,\n",
    "    ek_codes=[\"EK1.1\", \"EK1.2\"],\n",
    "    lo_codes=[\"LO1.1\", \"LO1.2\"],\n",
    "    target_difficulty=Difficulty.ANALYZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Generation Cycle\n",
    "\n",
    "Generate questions and run them through QC and fix cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a complete generation cycle\n",
    "cycle_result = run_generation(config)\n",
    "\n",
    "# Check the results\n",
    "if cycle_result.status == \"complete\":\n",
    "    print(\"Generation successful!\")\n",
    "    print(\"\\nFinal Question:\")\n",
    "    print(cycle_result.final_question.text)\n",
    "    print(\"\\nResponses:\")\n",
    "    for response in cycle_result.final_question.responses:\n",
    "        print(f\"- {'(Correct) ' if response.is_correct else ''}{response.text}\")\n",
    "else:\n",
    "    print(\"Generation failed\")\n",
    "    print(\"\\nQC Results:\")\n",
    "    for result in cycle_result.qc_results:\n",
    "        if result.score == 0:\n",
    "            print(f\"Failed check: {result.rationale}\")\n",
    "            print(f\"Feedback: {result.feedback}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review QC Results\n",
    "\n",
    "Examine the quality check results in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed QC results\n",
    "print(\"Quality Check Results:\")\n",
    "for result in cycle_result.qc_results:\n",
    "    print(f\"\\nScore: {result.score}\")\n",
    "    print(f\"Rationale: {result.rationale}\")\n",
    "    print(f\"Feedback: {result.feedback}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
